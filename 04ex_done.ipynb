{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSEMN Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Create a random list of number and then save it to a text file named \"simple_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "with open(\"simple_data.txt\", 'w') as file:\n",
    "        file.write(str(np.random.rand(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Create a random matrix of 5x5 and then save it to a text file named \"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69646919 0.28613933 0.22685145 0.55131477 0.71946897\n",
      " 0.42310646 0.9807642  0.68482974 0.4809319  0.39211752\n",
      " 0.34317802 0.72904971 0.43857224 0.0596779  0.39804426\n",
      " 0.73799541 0.18249173 0.17545176 0.53155137 0.53182759\n",
      " 0.63440096 0.84943179 0.72445532 0.61102351 0.72244338\n"
     ]
    }
   ],
   "source": [
    "with open (\"data.txt\" , 'w') as dt:\n",
    "    np.random.seed(123)\n",
    "    x=np.random.rand(25)\n",
    "    x=x.reshape(5,5)\n",
    "    \n",
    "    z=str(x).replace('[','').replace(']','') # To remove the parentesis that cause problem on reading after\n",
    "    print(z)\n",
    "    dt.write(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the saved txt file of point 2 and convert it to a csv file (by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data.txt\" , 'r') as dtr:\n",
    "\n",
    "    data=np.loadtxt(dtr)\n",
    "    tmp=data.tolist()\n",
    "    \n",
    "    with open (\"data.csv\",'w') as csvv:\n",
    "        for i in tmp:\n",
    "            csvv.write(str(i).replace('[','').replace(']','') +'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. load the binary file named *credit_card.dat* and convert the data into the real credit-card number.\n",
    "Each line correspond to a credit card number.\n",
    "Each character is composed by 6 bit (even the space) and the last 4 bit are just a padding\n",
    "\n",
    "**hint**: use the `chr()` function to convert a number to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Credit card: ---> [7 6 4 8 5 6 7 3 3 7 7 5 2 2 7 1]\n",
      "2 Credit card: ---> [3 2 5 7 8 2 4 7 3 3 5 4 2 2 6 6]\n",
      "3 Credit card: ---> [2 7 2 2 0 0 0 1 4 0 1 1 6 6 5 2]\n",
      "4 Credit card: ---> [0 6 6 1 3 0 6 3 3 7 4 2 3 1 5 0]\n",
      "5 Credit card: ---> [0 4 3 2 1 6 0 8 1 4 6 2 4 7 4 2]\n",
      "6 Credit card: ---> [5 8 2 7 2 0 2 7 8 7 8 5 7 3 0 3]\n",
      "7 Credit card: ---> [5 7 7 4 8 5 2 8 2 0 8 7 1 1 1 7]\n",
      "8 Credit card: ---> [8 1 4 0 1 2 1 0 6 3 5 2 2 8 4 5]\n",
      "9 Credit card: ---> [5 7 6 4 1 1 3 3 7 3 0 1 7 1 0 0]\n",
      "10 Credit card: ---> [6 4 5 6 1 7 3 7 4 1 2 6 6 7 2 6]\n",
      "11 Credit card: ---> [1 2 2 8 8 6 3 1 7 3 8 2 0 0 0 0]\n",
      "12 Credit card: ---> [7 0 5 1 0 1 6 0 5 3 7 4 3 1 6 6]\n",
      "13 Credit card: ---> [0 6 1 8 3 5 8 7 1 6 3 0 6 3 7 6]\n",
      "14 Credit card: ---> [1 5 4 5 5 4 5 4 7 4 4 4 5 6 3 6]\n",
      "15 Credit card: ---> [6 7 3 5 3 1 1 6 3 2 0 2 6 8 3 4]\n",
      "16 Credit card: ---> [7 2 8 7 5 0 1 1 1 5 4 7 8 4 1 3]\n",
      "17 Credit card: ---> [7 0 3 3 2 6 0 7 3 3 2 8 4 2 0 0]\n",
      "18 Credit card: ---> [2 5 6 8 5 2 4 4 1 8 7 4 5 0 2 4]\n",
      "19 Credit card: ---> [1 6 8 4 2 2 5 3 7 5 7 0 7 1 1 8]\n",
      "20 Credit card: ---> [0 6 7 2 2 5 7 6 0 5 7 5 6 6 3 1]\n",
      "21 Credit card: ---> [6 3 3 2 8 3 5 3 8 7 8 7 1 3 4 0]\n",
      "22 Credit card: ---> [1 8 1 3 3 3 6 1 1 1 7 5 4 2 1 1]\n",
      "23 Credit card: ---> [2 4 7 7 6 4 5 0 8 8 4 0 2 3 6 8]\n",
      "24 Credit card: ---> [5 5 1 2 3 5 0 5 2 5 6 3 1 3 2 6]\n",
      "25 Credit card: ---> [3 0 8 3 7 8 8 2 0 6 2 1 0 0 2 5]\n",
      "26 Credit card: ---> [4 5 2 1 5 1 4 8 8 0 4 5 0 3 3 4]\n",
      "27 Credit card: ---> [7 5 6 3 3 6 5 4 8 7 1 3 5 7 8 7]\n",
      "28 Credit card: ---> [8 3 2 4 2 6 6 4 0 4 7 6 5 5 6 1]\n",
      "29 Credit card: ---> [0 5 6 5 2 5 0 4 7 1 6 8 3 5 1 0]\n",
      "30 Credit card: ---> [5 1 0 7 5 5 0 7 1 7 6 7 0 7 3 8]\n",
      "31 Credit card: ---> [2 4 6 2 1 8 2 1 2 4 4 8 1 4 4 3]\n",
      "32 Credit card: ---> [2 7 8 8 0 6 3 8 6 8 6 1 6 5 5 4]\n",
      "33 Credit card: ---> [5 8 5 1 5 8 7 3 5 4 7 4 0 5 4 7]\n",
      "34 Credit card: ---> [0 6 7 0 1 0 0 4 4 0 1 3 2 6 5 5]\n",
      "35 Credit card: ---> [5 8 7 4 5 5 0 6 3 0 4 8 0 8 0 6]\n",
      "36 Credit card: ---> [2 8 0 5 5 4 0 1 8 4 6 2 1 2 6 0]\n",
      "37 Credit card: ---> [5 0 8 3 8 4 0 6 6 3 1 0 1 8 6 2]\n",
      "38 Credit card: ---> [1 0 7 6 1 4 4 5 3 0 1 3 2 2 6 6]\n",
      "39 Credit card: ---> [8 4 4 0 4 8 0 4 4 8 4 4 5 2 7 7]\n",
      "40 Credit card: ---> [4 7 5 8 6 1 4 1 0 6 8 6 1 3 8 7]\n",
      "41 Credit card: ---> [7 5 8 6 0 6 7 5 0 3 1 5 2 5 6 8]\n",
      "42 Credit card: ---> [2 5 4 4 1 2 5 8 7 4 3 2 5 1 6 5]\n",
      "43 Credit card: ---> [3 4 7 4 5 0 2 3 4 4 3 4 5 6 2 6]\n",
      "44 Credit card: ---> [1 4 1 0 0 2 7 0 0 4 3 4 5 0 8 6]\n",
      "45 Credit card: ---> [7 3 1 5 4 4 4 6 1 1 0 4 4 2 1 5]\n",
      "46 Credit card: ---> [0 2 2 4 7 7 4 2 8 3 0 0 0 2 6 6]\n",
      "47 Credit card: ---> [0 1 7 0 2 7 0 0 3 1 4 5 0 6 4 0]\n",
      "48 Credit card: ---> [2 0 0 6 2 4 3 7 8 0 5 4 1 6 0 0]\n",
      "49 Credit card: ---> [8 1 4 2 4 0 5 5 1 7 7 6 0 0 2 6]\n",
      "50 Credit card: ---> [3 0 2 6 7 3 8 0 1 2 4 1 1 0 8 4]\n"
     ]
    }
   ],
   "source": [
    "with open (\"credit_card.dat\" , 'r') as cc:\n",
    "    #(6 bit) every number [x4], (6 bit) every space [x3], last 4 bit padding\n",
    "    \n",
    "    ccard=np.empty((0,16),int)\n",
    "    for line in cc:\n",
    "        word_counter=0\n",
    "        word_size = 6\n",
    "        cc_linel=[]\n",
    "        if len(line)>118: # to be sure to not compute line without at least 118bit\n",
    "            for i in range(0, len(line),word_size):\n",
    "                word_counter+=1\n",
    "            \n",
    "                if word_counter%5 != 0:\n",
    "                    numb=chr(int('0b'+ str(line[i:word_size*word_counter]),2))\n",
    "                \n",
    "                    cc_linel.append(int(numb))\n",
    "            \n",
    "            linecc=np.array(cc_linel).reshape(1,16)\n",
    "\n",
    "            ccard=np.append(ccard, linecc,axis=0)\n",
    "    \n",
    "    for i in range (ccard.shape[0]):\n",
    "        print('%i Credit card: --->'%(i+1),ccard[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Load the file \"user_data.json\", filter the data by the \"CreditCardType\" field equals to \"American Express\". Than save the data a to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 people that have \"American Express\" and their full contact informations\n",
      "are available also on \"user_data.csv\":\n",
      "\n",
      " ['ID', 'JobTitle', 'EmailAddress', 'CreditCard', 'CreditCardType']\n",
      "2, Investment  Advisor, Clint_Thorpe5003@bulaffy.com, 7083-8766-0251-2345, American Express\n",
      "12, Retail Trainee, Phillip_Carpenter9505@famism.biz, 3657-0088-0820-5247, American Express\n",
      "28, Project Manager, Russel_Graves1378@extex.org, 6718-4818-8011-6024, American Express\n",
      "39, Stockbroker, Leanne_Newton1268@typill.biz, 5438-0816-4166-4847, American Express\n",
      "57, Budget Analyst, Tony_Giles1960@iatim.tech, 8130-3425-7573-7745, American Express\n",
      "62, CNC Operator, Owen_Allcott5125@bauros.biz, 4156-0107-7210-2630, American Express\n",
      "68, Project Manager, Liam_Lynn3280@kideod.biz, 7152-3247-6053-2233, American Express\n",
      "74, Dentist, Regina_Woodcock5820@yahoo.com, 0208-1753-3870-8002, American Express\n",
      "81, HR Specialist, Carter_Wallace9614@atink.com, 4256-7201-6717-4322, American Express\n",
      "92, Staffing Consultant, Maia_Stark2797@jiman.org, 3851-1403-1734-6321, American Express\n",
      "97, Stockbroker, Ciara_Lomax982@bauros.biz, 3702-3440-2472-5424, American Express\n",
      "116, Staffing Consultant, Isabel_Ellwood1475@fuliss.net, 3738-0882-0066-6683, American Express\n",
      "148, CNC Operator, Abdul_Townend2202@infotech44.tech, 4224-1226-3557-3448, American Express\n",
      "150, Fabricator, Caleb_Poulton1735@atink.com, 8203-6875-5225-0341, American Express\n",
      "151, Restaurant Manager, Ronald_Lewis6777@deavo.com, 7212-0155-5014-8471, American Express\n",
      "154, Bellman, Faith_Seymour3829@twace.org, 4170-5186-6887-6558, American Express\n",
      "169, Assistant Buyer, Anthony_Hancock9083@qater.org, 0832-3357-6010-6550, American Express\n",
      "176, Healthcare Specialist, Isabella_Willson5478@nanoff.biz, 5177-4868-4623-0384, American Express\n",
      "182, Pharmacist, Stephanie_Darcy3298@bauros.biz, 0264-4020-5106-5576, American Express\n",
      "199, Investment  Advisor, Ryan_Kennedy5565@corti.com, 3166-6287-6242-7207, American Express\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "with open('user_data.csv', 'w') as filecsv:\n",
    "    \n",
    "    lis=[\"ID\",\"JobTitle\", \"EmailAddress\", \"CreditCard\",\"CreditCardType\"]\n",
    "    \n",
    "    filecsv.write(str(lis)+'\\n')\n",
    "\n",
    "    data = json.load(open('user_data.json'))\n",
    "\n",
    "    filt_cc = 'American Express'\n",
    "    counter=0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        IDs=data[i][lis[0]]\n",
    "        JT=data[i][lis[1]]\n",
    "        EA=data[i][lis[2]]\n",
    "        CC=data[i][lis[3]]\n",
    "        CCT=data[i][lis[4]]\n",
    "    \n",
    "        if CCT==filt_cc:\n",
    "            counter+=1\n",
    "            lis_filtered=[IDs,JT,EA,CC,CCT]\n",
    "            filecsv.write(str(lis_filtered).replace('[','').replace(']','\\n').replace(\"'\",''))\n",
    "            \n",
    "    print('There are %i people that have \"American Express\" and their full contact informations\\nare available also on \"user_data.csv\":'%counter)\n",
    "\n",
    "with open('user_data.csv', 'r') as filecsv:\n",
    "    print('\\n',filecsv.read())\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Load the file from this url: [https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1](https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1) with Pandas. \n",
    "+ Explore the data (see the info of the data)\n",
    "+ Draw the istogram of the 'class' field. Decribe what you see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-09 11:46:38--  https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.69.1, 2620:100:6025:1::a27d:4501\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.69.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/7u3lm737ogbqsg8/mushrooms_categorized.csv [following]\n",
      "--2020-11-09 11:46:38--  https://www.dropbox.com/s/dl/7u3lm737ogbqsg8/mushrooms_categorized.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc83fcdae34fc4b5bc295d6e4eef.dl.dropboxusercontent.com/cd/0/get/BC1pyVU-GC_hqtp2-LubmpHM1RN6HJwdlGunUiqsIHAH5XqF9PfJFGH686cFGtg8ccQD4UljMDKQL1fnHOQJ0Q28tULnkB1uQJbjVBBk3B7nug/file?dl=1# [following]\n",
      "--2020-11-09 11:46:39--  https://uc83fcdae34fc4b5bc295d6e4eef.dl.dropboxusercontent.com/cd/0/get/BC1pyVU-GC_hqtp2-LubmpHM1RN6HJwdlGunUiqsIHAH5XqF9PfJFGH686cFGtg8ccQD4UljMDKQL1fnHOQJ0Q28tULnkB1uQJbjVBBk3B7nug/file?dl=1\n",
      "Resolving uc83fcdae34fc4b5bc295d6e4eef.dl.dropboxusercontent.com (uc83fcdae34fc4b5bc295d6e4eef.dl.dropboxusercontent.com)... 162.125.69.15, 2620:100:6025:15::a27d:450f\n",
      "Connecting to uc83fcdae34fc4b5bc295d6e4eef.dl.dropboxusercontent.com (uc83fcdae34fc4b5bc295d6e4eef.dl.dropboxusercontent.com)|162.125.69.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 375292 (366K) [application/binary]\n",
      "Saving to: ‘/home/francescofontana/data/mushrooms_categorized.csv?dl=1’\n",
      "\n",
      "mushrooms_categoriz 100%[===================>] 366.50K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-11-09 11:46:40 (2.51 MB/s) - ‘/home/francescofontana/data/mushrooms_categorized.csv?dl=1’ saved [375292/375292]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1 -P ~/data/\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute '_get_numeric_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-c2f4693fc448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclass_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class:'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mhist_frame\u001b[0;34m(data, column, by, grid, xlabelsize, xrot, ylabelsize, yrot, ax, sharex, sharey, figsize, layout, bins, backend, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \"\"\"\n\u001b[1;32m    192\u001b[0m     \u001b[0mplot_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_plot_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     return plot_backend.hist_frame(\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/plotting/_matplotlib/hist.py\u001b[0m in \u001b[0;36mhist_frame\u001b[0;34m(data, column, by, grid, xlabelsize, xrot, ylabelsize, yrot, ax, sharex, sharey, figsize, layout, bins, **kwds)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m     \u001b[0mnaxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute '_get_numeric_data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "file_name=\"/home/francescofontana/data/mushrooms_categorized.csv?dl=1\"\n",
    "data=pd.read_csv(file_name,nrows=8125,skiprows=range(1,1))\n",
    "data\n",
    "\n",
    "class_plot=pd.DataFrame.hist({'class:'})\n",
    "plot(class_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Load the remote file [https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1](https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1) with Pandas and plot a scatter plot all possible combination of the following fields:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Load the same file of point 6, and convert the file to json with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
