{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Maximum wind speed prediction at the Sprogø station**\n",
    "\n",
    "The exercise goal is to predict the maximum wind speed occurring every 50 years even if no measure exists for such a period. The available data are only measured over 21 years at the Sprogø meteorological station located in Denmark. \n",
    "\n",
    "The annual maxima are supposed to fit a normal probability density function. However such function is not going to be estimated because it gives a probability from a wind speed maxima. Finding the maximum wind speed occurring every 50 years requires the opposite approach, the result needs to be found from a defined probability. That is the quantile function role and the exercise goal will be to find it. In the current model, it is supposed that the maximum wind speed occurring every 50 years is defined as the upper 2% quantile.\n",
    "\n",
    "By definition, the quantile function is the inverse of the cumulative distribution function. The latter describes the probability distribution of an annual maxima. In the exercise, the cumulative probability $p_i$ for a given year i is defined as $p_i = i/(N+1)$ with $N = 21$, the number of measured years. Thus it will be possible to calculate the cumulative probability of every measured wind speed maxima. From those experimental points, the scipy.interpolate module will be very useful for fitting the quantile function. Finally the 50 years maxima is going to be evaluated from the cumulative probability of the 2% quantile.\n",
    "\n",
    "Practically, load the dataset:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "max_speeds = np.load('max-speeds.npy')\n",
    "years_nb = max_speeds.shape[0]\n",
    "```\n",
    "\n",
    "Compute then the cumulative probability $p_i$ (`cprob`) and sort the maximum speeds from the data. Use then the  UnivariateSpline from scipy.interpolate to define a quantile function and thus estimate the probabilities.\n",
    "\n",
    "In the current model, the maximum wind speed occurring every 50 years is defined as the upper 2% quantile. As a result, the cumulative probability value will be:\n",
    "\n",
    "```python\n",
    "fifty_prob = 1. - 0.02\n",
    "```\n",
    "\n",
    "So the storm wind speed occurring every 50 years can be guessed as:\n",
    "\n",
    "``` python\n",
    "fifty_wind = quantile_func(fifty_prob)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "max_speeds = np.load('max-speeds.npy')\n",
    "years_nb = max_speeds.shape[0]\n",
    "years = np.linspace(1, years_nb, years_nb)\n",
    "cprob = [i/(years_nb + 1) for i in years]\n",
    "max_speeds = np.sort(max_speeds)\n",
    "\n",
    "plt.plot(cprob, max_speeds,'x', label='Observed Data')\n",
    "quantile_f = UnivariateSpline(cprob, max_speeds)\n",
    "plt.plot(cprob, quantile_f(cprob), label='Predicted Data')\n",
    "plt.legend()\n",
    "\n",
    "fifty_prob = 1. - 0.02\n",
    "fifty_wind = quantile_f(fifty_prob)\n",
    "print('\\nThe guessed storm wind speed occurring every 50 years is:', fifty_wind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **Curve fitting of temperature in Alaska** \n",
    "\n",
    "The temperature extremes in Alaska for each month, starting in January, are given by (in degrees Celcius):\n",
    "\n",
    "max:  17,  19,  21,  28,  33,  38, 37,  37,  31,  23,  19,  18\n",
    "\n",
    "min: -62, -59, -56, -46, -32, -18, -9, -13, -25, -46, -52, -58\n",
    "\n",
    "* Plot these temperature extremes.\n",
    "* Define a function that can describe min and max temperatures. \n",
    "* Fit this function to the data with scipy.optimize.curve_fit().\n",
    "* Plot the result. Is the fit reasonable? If not, why?\n",
    "* Is the time offset for min and max temperatures the same within the fit accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy import optimize\n",
    "\n",
    "max_temp = np.array([17, 19, 21, 28, 33, 38, 37, 37, 31, 23, 19, 18])\n",
    "min_temp = np.array([-62, -59, -56, -46, -32, -18, -9, -13, -25, -46, -52, -58])\n",
    "\n",
    "months = np.linspace(1, 12, 12)\n",
    "plt.scatter(months, max_temp, color='red', label='Max Temperature')\n",
    "plt.scatter(months, min_temp, color='blue', label='Min Temperature')\n",
    "\n",
    "# Define gaussian function\n",
    "def gaussian(x, mean, sigma, amp, off):\n",
    "    return amp*norm.pdf(x, mean, sigma) + off\n",
    "\n",
    "# For the case of optimizing min temperature I added an initial guess of the parameters \n",
    "# in order to obtain a good result. Otherwise it doesn't work.\n",
    "\n",
    "max_p, max_p_cov = optimize.curve_fit(gaussian, months, max_temp)\n",
    "min_p, min_p_cov = optimize.curve_fit(gaussian, months, min_temp, p0=[7, 1, 1, -60])\n",
    "\n",
    "plt.plot(months, gaussian(months, *max_p), color='red', label='Max T predicted')\n",
    "plt.plot(months, gaussian(months, *min_p), color='blue', label='Min T predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **2D minimization of a six-hump camelback function**\n",
    "\n",
    "$$\n",
    "f(x,y) = \\left(4-2.1x^2+\\frac{x^4}{3} \\right) x^2 +xy + (4y^2 -4)y^2\n",
    "$$\n",
    "\n",
    "has multiple global and local minima. Find the global minima of this function.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* Variables can be restricted to $-2 < x < 2$ and $-1 < y < 1$.\n",
    "* Use numpy.meshgrid() and pylab.imshow() to find visually the regions.\n",
    "* Use scipy.optimize.minimize(), optionally trying out several of its methods.\n",
    "\n",
    "How many global minima are there, and what is the function value at those points? What happens for an initial guess of $(x, y) = (0, 0)$ ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    return (4 - 2.1*(x**2) + (x**4)/3)*(x**2) + x*y + (4*(y**2) - 4)*(y**2)\n",
    "def f_p(x):\n",
    "    return (4 - 2.1*(x[0]**2) + (x[0]**4)/3)*(x[0]**2) + x[0]*x[1] + (4*(x[1]**2) - 4)*(x[1]**2)\n",
    "\n",
    "N = 100\n",
    "x = np.linspace(-2,2,N)\n",
    "y = np.linspace(-1,1,N)\n",
    "\n",
    "x_v, y_v = np.meshgrid(x, y)\n",
    "\n",
    "plt.imshow(f(x_v, y_v), extent=[-2, 2, -1, 1])\n",
    "plt.colorbar()\n",
    "\n",
    "# We can see that there are two global minimal and this is due to the fact\n",
    "# that the function is an even function f(x,y)=f(-x,-y) and two local minima\n",
    "\n",
    "#First initial guess\n",
    "x1 = [0, -1]\n",
    "min1 = optimize.minimize(f_p, x1)\n",
    "print('First global min in:', min1.x)\n",
    "\n",
    "#Second initial guess\n",
    "x2 = [0, 1]\n",
    "min2 = optimize.minimize(f_p, x2)\n",
    "print('Second global min in:', min2.x)\n",
    "\n",
    "#Initial guess (0,0)\n",
    "x0 = [0,0]\n",
    "min0 = optimize.minimize(f_p, x0)\n",
    "print('Result obtained starting from point (0,0):', min0.fun)\n",
    "# It means that (0,0) is a saddle point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **FFT of a simple dataset**\n",
    "\n",
    "Performe a periodicity analysis on the lynxs-hares population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "\n",
    "data = np.loadtxt('populations.txt')\n",
    "year, hares, lynxes, carrots = data.T\n",
    "\n",
    "plt.plot( year, hares, year, lynxes, year, carrots ) \n",
    "plt.legend( ('Hare', 'Lynx', 'Carrot') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_hares = fftpack.fft(hares)\n",
    "fft_lynxes = fftpack.fft(lynxes)\n",
    "sample_freq = fftpack.fftfreq(year.size)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sample_freq, np.abs(fft_hares), label='Hares')\n",
    "plt.plot(sample_freq, np.abs(fft_lynxes), label='Lynxes')\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **FFT of an image**\n",
    "\n",
    "* Examine the provided image `moonlanding.png`, which is heavily contaminated with periodic noise. In this exercise, we aim to clean up the noise using the Fast Fourier Transform.\n",
    "* Load the image using pylab.imread().\n",
    "* Find and use the 2-D FFT function in scipy.fftpack, and plot the spectrum (Fourier transform of) the image. Do you have any trouble visualising the spectrum? If so, why?\n",
    "* The spectrum consists of high and low frequency components. The noise is contained in the high-frequency part of the spectrum, so set some of those components to zero (use array slicing).\n",
    "* Apply the inverse Fourier transform to see the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread(\"moonlanding.png\")\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (15,10))\n",
    "ax1.imshow(image, plt.cm.gray)\n",
    "ax1.set_title(\"Original Image\")\n",
    "\n",
    "image_fft = fftpack.fft2(image)\n",
    "spectrum = np.abs(image_fft)\n",
    "ax2.plot(spectrum)\n",
    "ax2.set_title('Spectrum')\n",
    "\n",
    "#Since there are many peaks, eliminate high frequency components\n",
    "filtered_fft = image_fft\n",
    "filtered_fft[spectrum > 2e3] = 0\n",
    "filtered_spectrum = np.abs(filtered_fft)\n",
    "ax3.plot(filtered_spectrum)\n",
    "ax3.set_title('Filtered Spectrum')\n",
    "\n",
    "filtered_image = fftpack.ifft2(filtered_fft).real\n",
    "ax4.imshow(filtered_image, plt.cm.gray)\n",
    "ax4.set_title(\"Filtered Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
